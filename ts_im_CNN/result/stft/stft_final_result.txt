Start Time : Sa 2. Sep 23:56:29 CEST 2023
Job ID: 1154374
Node: cc1g03
Partition: gpu_normal_stud
CPU cores: 16
Memory: 122880
GPUs: 0
Python environment: khoa                  *  /home/phamanh/anaconda3/envs/khoa
Current work directory: /home/phamanh/Schreibtisch/bachelorarbeit/ts_im_CNN

device: cuda


Study statistics: 
  Number of finished trials:  100
  Number of pruned trials:  39
  Number of complete trials:  61
  Value:  0.0174945778035103
  Params: 
    batch_size: 32
    drop: 0.3270781331969716
    epochs: 100
    hop: 256
    lr: 0.002777669598115583
    optimizer: SGD
    w_stft: 4352
    weight_decay: 0.054890102372538746
final test best model
https://app.neptune.ai/ba-final/stft-2/e/STFT-434
=====================================================================================
Layer (type:depth-idx)                                       Param #
=====================================================================================
ConcatModel                                                  --
├─EfficientNet: 1-1                                          --
│    └─Sequential: 2-1                                       --
│    │    └─Conv2dNormActivation: 3-1                        640
│    │    └─Sequential: 3-2                                  1,448
│    │    └─Sequential: 3-3                                  16,714
│    │    └─Sequential: 3-4                                  46,640
│    │    └─Sequential: 3-5                                  242,930
│    │    └─Sequential: 3-6                                  543,148
│    │    └─Sequential: 3-7                                  2,026,348
│    │    └─Sequential: 3-8                                  717,232
│    │    └─Conv2dNormActivation: 3-9                        412,160
│    └─AdaptiveAvgPool2d: 2-2                                --
│    └─Identity: 2-3                                         --
├─Conv1dNeuralNetwork: 1-2                                   --
│    └─Conv1DBlock_1: 2-4                                    --
│    │    └─Conv1d: 3-10                                     2,944
│    │    └─BatchNorm1d: 3-11                                256
│    │    └─ReLU: 3-12                                       --
│    └─Sequential: 2-5                                       --
│    │    └─Conv1DBlock_2: 3-13                              99,072
│    │    └─Conv1DBlock_2: 3-14                              99,072
│    └─Conv1DBlock_2: 2-6                                    --
│    │    └─Conv1d: 3-15                                     49,280
│    │    └─BatchNorm1d: 3-16                                256
│    │    └─ReLU: 3-17                                       --
│    │    └─Conv1d: 3-18                                     49,280
│    │    └─BatchNorm1d: 3-19                                256
│    │    └─ReLU: 3-20                                       --
│    │    └─MaxPool1d: 3-21                                  --
│    └─Conv2DBlock: 2-7                                      --
│    │    └─Conv2d: 3-22                                     4,736
│    │    └─BatchNorm2d: 3-23                                256
│    │    └─ReLU: 3-24                                       --
│    │    └─Conv2d: 3-25                                     147,584
│    │    └─BatchNorm2d: 3-26                                256
│    │    └─ReLU: 3-27                                       --
│    │    └─MaxPool2d: 3-28                                  --
│    └─Conv2DBlock: 2-8                                      --
│    │    └─Conv2d: 3-29                                     147,584
│    │    └─BatchNorm2d: 3-30                                256
│    │    └─ReLU: 3-31                                       --
│    │    └─Conv2d: 3-32                                     147,584
│    │    └─BatchNorm2d: 3-33                                256
│    │    └─ReLU: 3-34                                       --
│    │    └─MaxPool2d: 3-35                                  --
│    └─Conv2DBlock: 2-9                                      --
│    │    └─Conv2d: 3-36                                     147,584
│    │    └─BatchNorm2d: 3-37                                256
│    │    └─ReLU: 3-38                                       --
│    │    └─Conv2d: 3-39                                     147,584
│    │    └─BatchNorm2d: 3-40                                256
│    │    └─ReLU: 3-41                                       --
│    │    └─MaxPool2d: 3-42                                  --
│    └─Conv2DBlock: 2-10                                     --
│    │    └─Conv2d: 3-43                                     147,584
│    │    └─BatchNorm2d: 3-44                                256
│    │    └─ReLU: 3-45                                       --
│    │    └─Conv2d: 3-46                                     147,584
│    │    └─BatchNorm2d: 3-47                                256
│    │    └─ReLU: 3-48                                       --
│    │    └─MaxPool2d: 3-49                                  --
│    └─Flatten: 2-11                                         --
├─Dropout: 1-3                                               --
├─Linear: 1-4                                                2,561
=====================================================================================
Total params: 5,350,109
Trainable params: 5,350,109
Non-trainable params: 0
=====================================================================================
Warning: string series 'monitoring/926ff44e/stdout' value was longer than 1000 characters and was truncated. This warning is printed only once per series.
Warning: string 'structure' value was longer than 16384 characters and was truncated. This warning is printed only once.
epoch 0, loss train 0.38, loss test 0.70, score train 0.21, score test 0.19, score final 0.00
epoch 1, loss train 0.27, loss test 1.90, score train 0.26, score test 0.30, score final 0.15
epoch 2, loss train 0.22, loss test 0.92, score train 0.29, score test 0.28, score final 0.06
epoch 3, loss train 0.21, loss test 0.61, score train 0.30, score test 0.34, score final 0.11
epoch 4, loss train 0.19, loss test 0.42, score train 0.31, score test 0.35, score final 0.03
epoch 5, loss train 0.18, loss test 0.74, score train 0.31, score test 0.32, score final 0.03
epoch 6, loss train 0.17, loss test 0.70, score train 0.33, score test 0.29, score final 0.09
epoch 7, loss train 0.16, loss test 0.42, score train 0.34, score test 0.30, score final 0.07
epoch 8, loss train 0.16, loss test 0.44, score train 0.35, score test 0.22, score final 0.11
epoch 9, loss train 0.15, loss test 1.07, score train 0.35, score test 0.27, score final 0.02
epoch 10, loss train 0.14, loss test 0.46, score train 0.36, score test 0.23, score final 0.09
epoch 11, loss train 0.14, loss test 1.16, score train 0.36, score test 0.30, score final 0.01
epoch 12, loss train 0.14, loss test 0.62, score train 0.36, score test 0.33, score final 0.01
epoch 13, loss train 0.13, loss test 0.72, score train 0.38, score test 0.26, score final 0.08
epoch 14, loss train 0.13, loss test 0.67, score train 0.37, score test 0.28, score final 0.01
epoch 15, loss train 0.13, loss test 0.34, score train 0.38, score test 0.26, score final 0.09
epoch 16, loss train 0.13, loss test 0.84, score train 0.37, score test 0.27, score final 0.03
epoch 17, loss train 0.12, loss test 1.48, score train 0.38, score test 0.26, score final 0.01
epoch 18, loss train 0.12, loss test 0.93, score train 0.40, score test 0.33, score final 0.02
epoch 19, loss train 0.12, loss test 0.84, score train 0.39, score test 0.31, score final 0.10
epoch 20, loss train 0.11, loss test 0.59, score train 0.41, score test 0.24, score final 0.14
epoch 21, loss train 0.11, loss test 0.43, score train 0.41, score test 0.29, score final 0.01
epoch 22, loss train 0.11, loss test 1.07, score train 0.41, score test 0.26, score final 0.07
epoch 23, loss train 0.11, loss test 1.44, score train 0.41, score test 0.19, score final 0.11
epoch 24, loss train 0.11, loss test 0.81, score train 0.42, score test 0.30, score final 0.01
epoch 25, loss train 0.11, loss test 1.52, score train 0.42, score test 0.29, score final 0.01
epoch 26, loss train 0.10, loss test 1.01, score train 0.43, score test 0.26, score final 0.01
epoch 27, loss train 0.09, loss test 1.10, score train 0.45, score test 0.23, score final 0.05
epoch 28, loss train 0.10, loss test 0.57, score train 0.43, score test 0.33, score final 0.01
epoch 29, loss train 0.10, loss test 0.41, score train 0.44, score test 0.32, score final 0.01
epoch 30, loss train 0.10, loss test 0.53, score train 0.44, score test 0.25, score final 0.01
epoch 31, loss train 0.09, loss test 0.83, score train 0.45, score test 0.27, score final 0.01
epoch 32, loss train 0.09, loss test 1.61, score train 0.45, score test 0.25, score final 0.02
epoch 33, loss train 0.10, loss test 0.46, score train 0.44, score test 0.31, score final 0.02
epoch 34, loss train 0.09, loss test 0.88, score train 0.45, score test 0.26, score final 0.01
epoch 35, loss train 0.09, loss test 0.96, score train 0.45, score test 0.30, score final 0.01
epoch 36, loss train 0.09, loss test 1.41, score train 0.46, score test 0.24, score final 0.12
epoch 37, loss train 0.09, loss test 1.05, score train 0.46, score test 0.30, score final 0.01
epoch 38, loss train 0.09, loss test 0.45, score train 0.46, score test 0.30, score final 0.01
epoch 39, loss train 0.08, loss test 0.72, score train 0.47, score test 0.24, score final 0.01
epoch 40, loss train 0.09, loss test 1.04, score train 0.47, score test 0.30, score final 0.01
epoch 41, loss train 0.09, loss test 1.18, score train 0.46, score test 0.28, score final 0.07
epoch 42, loss train 0.09, loss test 1.25, score train 0.47, score test 0.28, score final 0.01
epoch 43, loss train 0.08, loss test 1.04, score train 0.46, score test 0.31, score final 0.01
epoch 44, loss train 0.08, loss test 1.02, score train 0.49, score test 0.27, score final 0.01
epoch 45, loss train 0.08, loss test 1.51, score train 0.49, score test 0.31, score final 0.01
epoch 46, loss train 0.08, loss test 0.51, score train 0.48, score test 0.29, score final 0.04
epoch 47, loss train 0.08, loss test 1.69, score train 0.49, score test 0.32, score final 0.01
epoch 48, loss train 0.08, loss test 0.73, score train 0.47, score test 0.30, score final 0.01
epoch 49, loss train 0.08, loss test 0.95, score train 0.49, score test 0.29, score final 0.01
epoch 50, loss train 0.08, loss test 0.42, score train 0.50, score test 0.27, score final 0.01
epoch 51, loss train 0.08, loss test 0.93, score train 0.50, score test 0.28, score final 0.01
epoch 52, loss train 0.07, loss test 0.69, score train 0.50, score test 0.28, score final 0.01
epoch 53, loss train 0.07, loss test 0.63, score train 0.51, score test 0.32, score final 0.01
epoch 54, loss train 0.07, loss test 0.55, score train 0.50, score test 0.27, score final 0.07
epoch 55, loss train 0.07, loss test 0.87, score train 0.50, score test 0.26, score final 0.07
epoch 56, loss train 0.07, loss test 0.46, score train 0.51, score test 0.29, score final 0.01
epoch 57, loss train 0.07, loss test 0.60, score train 0.50, score test 0.23, score final 0.03
epoch 58, loss train 0.07, loss test 0.77, score train 0.50, score test 0.28, score final 0.01
epoch 59, loss train 0.07, loss test 2.30, score train 0.51, score test 0.27, score final 0.02
epoch 60, loss train 0.07, loss test 1.37, score train 0.51, score test 0.29, score final 0.01
epoch 61, loss train 0.07, loss test 0.43, score train 0.52, score test 0.30, score final 0.01
epoch 62, loss train 0.07, loss test 0.64, score train 0.53, score test 0.29, score final 0.01
epoch 63, loss train 0.07, loss test 0.39, score train 0.52, score test 0.28, score final 0.01
epoch 64, loss train 0.07, loss test 0.50, score train 0.52, score test 0.30, score final 0.01
epoch 65, loss train 0.07, loss test 1.63, score train 0.53, score test 0.28, score final 0.02
epoch 66, loss train 0.07, loss test 0.51, score train 0.53, score test 0.28, score final 0.01
epoch 67, loss train 0.07, loss test 1.58, score train 0.52, score test 0.30, score final 0.02
epoch 68, loss train 0.06, loss test 0.74, score train 0.54, score test 0.27, score final 0.01
epoch 69, loss train 0.06, loss test 0.86, score train 0.54, score test 0.29, score final 0.01
epoch 70, loss train 0.06, loss test 1.35, score train 0.53, score test 0.34, score final 0.01
epoch 71, loss train 0.06, loss test 0.40, score train 0.54, score test 0.29, score final 0.04
epoch 72, loss train 0.07, loss test 1.50, score train 0.53, score test 0.31, score final 0.01
epoch 73, loss train 0.06, loss test 0.55, score train 0.53, score test 0.32, score final 0.01
epoch 74, loss train 0.06, loss test 1.66, score train 0.54, score test 0.29, score final 0.01
epoch 75, loss train 0.06, loss test 1.02, score train 0.54, score test 0.28, score final 0.01
epoch 76, loss train 0.06, loss test 1.26, score train 0.54, score test 0.30, score final 0.01
epoch 77, loss train 0.06, loss test 0.47, score train 0.54, score test 0.32, score final 0.01
epoch 78, loss train 0.06, loss test 0.85, score train 0.54, score test 0.32, score final 0.01
epoch 79, loss train 0.06, loss test 1.53, score train 0.55, score test 0.27, score final 0.01
epoch 80, loss train 0.06, loss test 1.45, score train 0.55, score test 0.30, score final 0.01
epoch 81, loss train 0.06, loss test 0.66, score train 0.55, score test 0.28, score final 0.01
epoch 82, loss train 0.06, loss test 0.76, score train 0.55, score test 0.31, score final 0.01
epoch 83, loss train 0.06, loss test 0.59, score train 0.55, score test 0.30, score final 0.01
epoch 84, loss train 0.06, loss test 0.62, score train 0.56, score test 0.31, score final 0.01
epoch 85, loss train 0.06, loss test 0.76, score train 0.56, score test 0.29, score final 0.01
epoch 86, loss train 0.06, loss test 0.94, score train 0.56, score test 0.30, score final 0.01
epoch 87, loss train 0.06, loss test 0.43, score train 0.56, score test 0.30, score final 0.01
epoch 88, loss train 0.06, loss test 0.68, score train 0.56, score test 0.28, score final 0.01
epoch 89, loss train 0.06, loss test 2.00, score train 0.57, score test 0.33, score final 0.01
epoch 90, loss train 0.06, loss test 0.80, score train 0.56, score test 0.26, score final 0.01
epoch 91, loss train 0.06, loss test 0.87, score train 0.57, score test 0.29, score final 0.01
epoch 92, loss train 0.06, loss test 1.37, score train 0.57, score test 0.27, score final 0.01
epoch 93, loss train 0.06, loss test 1.47, score train 0.57, score test 0.30, score final 0.01
epoch 94, loss train 0.06, loss test 0.73, score train 0.58, score test 0.33, score final 0.01
epoch 95, loss train 0.06, loss test 0.28, score train 0.58, score test 0.31, score final 0.01
epoch 96, loss train 0.05, loss test 0.36, score train 0.59, score test 0.31, score final 0.01
epoch 97, loss train 0.05, loss test 0.36, score train 0.59, score test 0.29, score final 0.01
epoch 98, loss train 0.05, loss test 1.45, score train 0.58, score test 0.27, score final 0.01
epoch 99, loss train 0.06, loss test 0.73, score train 0.57, score test 0.31, score final 0.01
Shutting down background jobs, please wait a moment...
Done!
Waiting for the remaining 14 operations to synchronize with Neptune. Do not kill this process.
All 14 operations synced, thanks for waiting!
Explore the metadata in the Neptune app:
https://app.neptune.ai/ba-final/stft-2/e/STFT-434/metadata
https://app.neptune.ai/ba-final/stft-2/e/STFT-435
=====================================================================================
Layer (type:depth-idx)                                       Param #
=====================================================================================
ConcatModel                                                  --
├─EfficientNet: 1-1                                          --
│    └─Sequential: 2-1                                       --
│    │    └─Conv2dNormActivation: 3-1                        640
│    │    └─Sequential: 3-2                                  1,448
│    │    └─Sequential: 3-3                                  16,714
│    │    └─Sequential: 3-4                                  46,640
│    │    └─Sequential: 3-5                                  242,930
│    │    └─Sequential: 3-6                                  543,148
│    │    └─Sequential: 3-7                                  2,026,348
│    │    └─Sequential: 3-8                                  717,232
│    │    └─Conv2dNormActivation: 3-9                        412,160
│    └─AdaptiveAvgPool2d: 2-2                                --
│    └─Identity: 2-3                                         --
├─Conv1dNeuralNetwork: 1-2                                   --
│    └─Conv1DBlock_1: 2-4                                    --
│    │    └─Conv1d: 3-10                                     2,944
│    │    └─BatchNorm1d: 3-11                                256
│    │    └─ReLU: 3-12                                       --
│    └─Sequential: 2-5                                       --
│    │    └─Conv1DBlock_2: 3-13                              99,072
│    │    └─Conv1DBlock_2: 3-14                              99,072
│    └─Conv1DBlock_2: 2-6                                    --
│    │    └─Conv1d: 3-15                                     49,280
│    │    └─BatchNorm1d: 3-16                                256
│    │    └─ReLU: 3-17                                       --
│    │    └─Conv1d: 3-18                                     49,280
│    │    └─BatchNorm1d: 3-19                                256
│    │    └─ReLU: 3-20                                       --
│    │    └─MaxPool1d: 3-21                                  --
│    └─Conv2DBlock: 2-7                                      --
│    │    └─Conv2d: 3-22                                     4,736
│    │    └─BatchNorm2d: 3-23                                256
│    │    └─ReLU: 3-24                                       --
│    │    └─Conv2d: 3-25                                     147,584
│    │    └─BatchNorm2d: 3-26                                256
│    │    └─ReLU: 3-27                                       --
│    │    └─MaxPool2d: 3-28                                  --
│    └─Conv2DBlock: 2-8                                      --
│    │    └─Conv2d: 3-29                                     147,584
│    │    └─BatchNorm2d: 3-30                                256
│    │    └─ReLU: 3-31                                       --
│    │    └─Conv2d: 3-32                                     147,584
│    │    └─BatchNorm2d: 3-33                                256
│    │    └─ReLU: 3-34                                       --
│    │    └─MaxPool2d: 3-35                                  --
│    └─Conv2DBlock: 2-9                                      --
│    │    └─Conv2d: 3-36                                     147,584
│    │    └─BatchNorm2d: 3-37                                256
│    │    └─ReLU: 3-38                                       --
│    │    └─Conv2d: 3-39                                     147,584
│    │    └─BatchNorm2d: 3-40                                256
│    │    └─ReLU: 3-41                                       --
│    │    └─MaxPool2d: 3-42                                  --
│    └─Conv2DBlock: 2-10                                     --
│    │    └─Conv2d: 3-43                                     147,584
│    │    └─BatchNorm2d: 3-44                                256
│    │    └─ReLU: 3-45                                       --
│    │    └─Conv2d: 3-46                                     147,584
│    │    └─BatchNorm2d: 3-47                                256
│    │    └─ReLU: 3-48                                       --
│    │    └─MaxPool2d: 3-49                                  --
│    └─Flatten: 2-11                                         --
├─Dropout: 1-3                                               --
├─Linear: 1-4                                                2,561
=====================================================================================
Total params: 5,350,109
Trainable params: 5,350,109
Non-trainable params: 0
=====================================================================================
Warning: string series 'monitoring/926ff44e/stdout' value was longer than 1000 characters and was truncated. This warning is printed only once per series.
Warning: string 'structure' value was longer than 16384 characters and was truncated. This warning is printed only once.
Tracking result from best trial in Cross Validation
loss test 0.14, score test 0.31
Bearing 13, RUL pred 8992, RUl true 5730
Bearing 14, RUL pred 258, RUl true 2890
Bearing 15, RUL pred 3372, RUl true 1610
Bearing 16, RUL pred 5127, RUl true 1460
Bearing 17, RUL pred 3215, RUl true 7570
Bearing 23, RUL pred 11432, RUl true 7530
Bearing 24, RUL pred 4532, RUl true 1390
Bearing 25, RUL pred 7466, RUl true 3090
Bearing 26, RUL pred 1703, RUl true 1290
Bearing 27, RUL pred 1892, RUl true 580
Bearing 33, RUL pred 1503, RUl true 820
score final 0.02
loss final 2682.43

Shutting down background jobs, please wait a moment...
Done!
Waiting for the remaining 5 operations to synchronize with Neptune. Do not kill this process.
All 5 operations synced, thanks for waiting!
Explore the metadata in the Neptune app:
https://app.neptune.ai/ba-final/stft-2/e/STFT-435/metadata

